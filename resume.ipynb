{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68deebc3-1ff4-4f6b-ab40-7373038fc572",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3edec9-6441-4f45-98ba-565b85dd26a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx2pdf import convert\n",
    "from IPython.display import display, IFrame\n",
    "import os\n",
    "import PyPDF2 as pdf\n",
    "from pyresparser import ResumeParser\n",
    "import spacy\n",
    "import tempfile\n",
    "from docx2pdf import convert\n",
    "import re\n",
    "import nltk\n",
    "from spacy.matcher import Matcher\n",
    "import constants as cs\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from pdfminer.high_level import extract_text\n",
    "import streamlit as st \n",
    "import base64\n",
    "import tempfile\n",
    "import pythoncom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d54765a-252c-4f9b-953f-7d1029d28fc3",
   "metadata": {},
   "source": [
    "## Creating StreamLit App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56eb4c80-a641-4437-be27-546295bb31d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 15:07:21.244 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\quadr\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "pythoncom.CoInitialize()\n",
    "\n",
    "def show_pdf(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        base64_pdf = base64.b64encode(f.read()).decode('utf-8')\n",
    "    # pdf_display = f'<embed src=\"data:application/pdf;base64,{base64_pdf}\" width=\"700\" height=\"1000\" type=\"application/pdf\">'\n",
    "    pdf_display = F'<div style=\"display: flex; justify-content: center;\"><iframe src=\"data:application/pdf; base64,{base64_pdf}\" width=\"1000\" height=\"1000\" type=\"application/pdf\"></iframe></div>'\n",
    "    st.markdown(pdf_display, unsafe_allow_html=True)\n",
    "\n",
    "def main():\n",
    "    st.set_page_config(layout=\"wide\")\n",
    "    # Set up the layout with three columns\n",
    "    col1, col2, col3 = st.columns([1, 2, 1])\n",
    "\n",
    "    # Load and display the GIF image in the left column (col1)\n",
    "    gif_path = 'Graphics/Resume Parser.gif'\n",
    "    with col1:\n",
    "        st.image(gif_path, use_column_width=True)  # Adjust the width as needed\n",
    "\n",
    "    # Display the text in the middle column (col2)\n",
    "    with col2:\n",
    "        st.markdown(\"<h1 style='text-align: center; font-size: 60px;'>Resume Parsing and Scoring App</h1>\", unsafe_allow_html=True)\n",
    "\n",
    "    logo_path = 'Graphics/AI Logo.png'\n",
    "    # Display the logo in the right column (col3)\n",
    "    with col3:\n",
    "        st.image(logo_path, use_column_width=True)  # Adjust the width as needed\n",
    "\n",
    "    pdf_file = st.file_uploader(\"Choose your Resume\", type=[\"pdf\", \"docx\"])\n",
    "    text = \"Hello\"\n",
    "    # Inputting job level\n",
    "    Job_level = [\"Senior management\", \"Middle management\", \"First-level management\", \"Experienced\", \"Intermediate\", \"Entry-level\"]\n",
    "    job_level_option = st.selectbox('What is your Job Level?', Job_level)\n",
    "    # Inputting required job skills\n",
    "    Job_skills = st.text_input(\"Please input a list of required skills for your job listing\", \"e.g Communication, MS Excel\")\n",
    "    # Inputting required major\n",
    "    major= [\"Architecture\", \"Biology\", \"Business_Administration\", \"Chemistry\", \"Criminal Justice\", \"Criminology\", \"Communications\", \"English\", \n",
    "          \"Computer_Science\",\"Cybersecurity\", \"Construction_Management\", \"Engineering\", \"Military_Science\", \"Nursing\", \"Psychology\", \"SWAP\"]\n",
    "    major_option = st.selectbox(\"What is Major is your Job Related to?\", major)\n",
    "\n",
    "    if pdf_file is not None:\n",
    "        if pdf_file.type == 'application/pdf':\n",
    "            st.write(\"You've uploaded a PDF file.\")\n",
    "            # Create a temporary PDF file path\n",
    "            pdf_path = tempfile.mktemp(suffix='.pdf')\n",
    "            # Save the uploaded PDF file to the temporary path\n",
    "            with open(pdf_path, 'wb') as f:\n",
    "                f.write(pdf_file.getbuffer())\n",
    "            show_pdf(pdf_path)\n",
    "            text = fn.read_text_from_pdf(pdf_path)\n",
    "\n",
    "        elif pdf_file.type == 'application/vnd.openxmlformats-officedocument.wordprocessingml.document':\n",
    "            st.write(\"You've uploaded a DOCX file.\")\n",
    "            doc_path = tempfile.mktemp(suffix='.docx')\n",
    "            # Save the uploaded PDF file to the temporary path\n",
    "            with open(doc_path, 'wb') as f:\n",
    "                f.write(pdf_file.getbuffer())\n",
    "            pdf_path = tempfile.mktemp(suffix='.pdf')\n",
    "            convert(doc_path, pdf_path)\n",
    "            show_pdf(pdf_path)\n",
    "            text = fn.read_text_from_pdf(pdf_path)\n",
    "            # Uninitialize COM\n",
    "            pythoncom.CoUninitialize()\n",
    "    st.markdown(\"<h1 style='text-align: center; font-size: 60px;'>Resume Analysis</h1>\", unsafe_allow_html=True)\n",
    "    # Calculating Resume Score\n",
    "    # Contact Info Score\n",
    "    contact_info_score = 20\n",
    "    if fn.extract_name(fn.nlp(text)) == None:\n",
    "        contact_info_score -= 5\n",
    "    if fn.extract_email(text) == None:\n",
    "        contact_info_score -= 5\n",
    "    if fn.extract_website(text) != None:\n",
    "        contact_info_score += 5\n",
    "    \n",
    "    st.subheader(\"Contact Information\\n\")\n",
    "    st.write(f\"**First Name:** {fn.extract_name(fn.nlp(text)).split()[0]}\\n\")\n",
    "    st.write(f\"**Last Name:** {fn.extract_name(fn.nlp(text)).split()[1]}\\n\")\n",
    "    st.write(f\"**Email:** {fn.extract_email(text)}\\n\")\n",
    "    st.write(f\"**Phone No:** {fn.remove_square_brackets(fn.extract_phone_numbers(text))}\\n\")\n",
    "    st.write(f\"**Websites:** {fn.extract_website(text)}\\n\")\n",
    "    st.subheader(\"Education\\n\")\n",
    "    ed = fn.extract_education_from_resume(text)\n",
    "    if ed:\n",
    "        education_score = 10\n",
    "        st.write(fn.extract_education_from_resume(text)[0])\n",
    "    else:\n",
    "        education_score = 0\n",
    "        st.write(\"Education not detected\")\n",
    "    st.subheader(\"Objective/Summary\\n\")\n",
    "    sections = fn.extract_entity_sections(text)\n",
    "    st.subheader(\"Relevant Skills\\n\")\n",
    "    relevant = fn.get_relevant_skills(major_option)\n",
    "    required = fn.get_required_skills(Job_skills)\n",
    "    soft = fn.get_soft_skills()\n",
    "    skills = fn.extract_skills(text,required,soft,relevant)\n",
    "    if skills:\n",
    "        st.write(fn.extract_skills(text,required,soft,relevant))\n",
    "    if \"summary\" in sections:\n",
    "        summary_score = 10\n",
    "        st.write(fn.remove_square_brackets(sections[\"summary\"]))\n",
    "    else:\n",
    "        summary_score = 0\n",
    "        st.write(\"Summary not detected\")\n",
    "    st.subheader(\"Experience\\n\")\n",
    "    if \"experience\" in sections:\n",
    "        experience_score = 10\n",
    "        st.write(fn.remove_square_brackets(sections[\"experience\"]))\n",
    "    else:\n",
    "        experience_score = 0\n",
    "        st.write(\"Experience not detected\")\n",
    "    st.subheader(\"Projects\\n\")\n",
    "    if \"projects\" in sections:\n",
    "        project_score = 10\n",
    "        st.write(fn.remove_square_brackets(sections[\"projects\"]))\n",
    "    else:\n",
    "        project_score = 0\n",
    "        st.write(\"Projects not detected\")\n",
    "    st.subheader(\"Honors\\n\")\n",
    "    if \"honors\" in sections:\n",
    "        honors_score = 10\n",
    "        st.write(fn.remove_square_brackets(sections[\"honors\"]))\n",
    "    else:\n",
    "        honors_score = 0\n",
    "        st.write(\"Honors not detected\")\n",
    "    st.subheader(\"Certificates\\n\")\n",
    "    if \"certificates\" in sections:\n",
    "        certificates_score = 10\n",
    "        st.write(fn.remove_square_brackets(sections[\"certificates\"]))\n",
    "    else:\n",
    "        certificates_score = 0\n",
    "        st.write(\"certificates not detected\")\n",
    "    st.subheader(\"Publications\\n\")\n",
    "    if \"publications\" in sections:\n",
    "        st.write(fn.remove_square_brackets(sections[\"publications\"]))\n",
    "    else:\n",
    "        st.write(\"publications not detected\")\n",
    "    st.subheader(\"Resume Score\\n\")\n",
    "    resume_score = skills_score + contact_info_score + certificates_score + honors_score + project_score + experience_score + summary_score\n",
    "    st.write(resume_score)\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a497763a-cc83-44fa-8cc0-f1c72d9b014b",
   "metadata": {},
   "source": [
    "## Creating List of Skills for Majors at Norwich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c96b692-7d24-451e-a87c-b4d80a5cd050",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code modified from https://medium.com/@2020.chetaniya.bajaj/building-a-resume-parser-using-nlp-dd36c2afbce9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b41b8d63-86e0-45fc-856d-b91b2573477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing for contact information\n",
    "import re\n",
    "import subprocess\n",
    "# Storing a phone number\n",
    "Phone_no = re.compile(r'[\\+\\(]?[1-9][0-9 .\\-\\(\\)]{8,}[0-9]')\n",
    "Email_address = re.compile(r'[a-zA-Z0-9\\.\\-+_]+@[a-zA-Z0-9\\.\\-+_]+\\.[a-z]+')\n",
    "web = re.compile(r'[a-zA-Z0-9\\.\\-+_]\\.\\+com[a-zA-Z0-9\\.\\-+_]')\n",
    "def extract_phone_number(resume):\n",
    "    phone = re.findall(Phone_no, resume)\n",
    "    if resume.find(phone[0]) >= 0 and len(phone[0]) <16:\n",
    "        return phone[0]\n",
    "    return None\n",
    "def extract_email(resume):\n",
    "    email = re.findall(Email_address,resume)\n",
    "    return email[0]\n",
    "def extract_website(resume):\n",
    "    website = re.findall(web, resume)\n",
    "    return website\n",
    "# Checking for email, phone_number and websites\n",
    "phone_number = extract_phone_number(text)\n",
    "email_address = extract_email(text)\n",
    "website_link = extract_website(text)\n",
    "# Calculating conctact info score\n",
    "contact_info_score = 5\n",
    "if len(phone_number)==0:\n",
    "    contact_info_score -= 1\n",
    "if len(email_address)==0:\n",
    "    contact_info_score -= 1\n",
    "if len(website_link)>0:\n",
    "    contact_info_score+=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "31a208a3-c7b8-4863-8c70-9bd4b31470c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\quadr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\quadr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing NLP\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "# Parsing resume for relevant skills \n",
    "\n",
    "def extract_skills(resume):\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    word_tokens = nltk.tokenize.word_tokenize(resume)\n",
    " \n",
    "    # remove the stop words\n",
    "    filtered_tokens = [w for w in word_tokens if w not in stop_words]\n",
    " \n",
    "    # remove the punctuation\n",
    "    filtered_tokens = [w for w in word_tokens if w.isalpha()]\n",
    " \n",
    "    # generate bigrams and trigrams (such as artificial intelligence)\n",
    "    bigrams_trigrams = list(map(' '.join, nltk.everygrams(filtered_tokens, 2, 3)))\n",
    " \n",
    "    # we create a set to keep the results in.\n",
    "    found_skills = set()\n",
    " \n",
    "    # we search for each token in our skills database\n",
    "    for token in filtered_tokens:\n",
    "        if token.lower() in skills:\n",
    "            found_skills.add(token)\n",
    " \n",
    "    # we search for each bigram and trigram in our skills database\n",
    "    for ngram in bigrams_trigrams:\n",
    "        if ngram.lower() in skills:\n",
    "            found_skills.add(ngram)\n",
    "\n",
    "    return found_skills\n",
    "skills = extract_skills(text)\n",
    "# Bug: Skills are repeated\n",
    "# Calculating skills score\n",
    "skills_score = len(skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "28995322-7d89-486f-8052-84e8ddbeeb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing resume for educational level\n",
    "EDUCATION = [\n",
    "    \"diploma\",\n",
    "    \"bachelor\",\n",
    "    \"master\",\n",
    "    \"associate\",\n",
    "    \"phd\"]\n",
    "\n",
    "def extract_education(resume):\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    word_tokens = nltk.tokenize.word_tokenize(resume)\n",
    " \n",
    "    # remove the stop words\n",
    "    filtered_tokens = [w for w in word_tokens if w not in stop_words]\n",
    " \n",
    "    # remove the punctuation\n",
    "    filtered_tokens = [w for w in word_tokens if w.isalpha()]\n",
    " \n",
    "    # generate bigrams and trigrams (such as artificial intelligence)\n",
    "    bigrams_trigrams = list(map(' '.join, nltk.everygrams(filtered_tokens, 2, 3)))\n",
    " \n",
    "    # we create a set to keep the results in.\n",
    "    found_edu = set()\n",
    " \n",
    "    # we search for each token in our skills database\n",
    "    for token in filtered_tokens:\n",
    "        if token.lower() in EDUCATION:\n",
    "            found_edu.add(token)\n",
    "    return found_edu\n",
    "\n",
    "education_level = extract_education(text)\n",
    "# Bug: Skills are repeated\n",
    "# Calculating education score\n",
    "education_score = 0\n",
    "for edu in education_level:\n",
    "    if edu.lower() == \"diploma\":\n",
    "        education_score += 1\n",
    "    elif edu.lower() == \"associate\":\n",
    "        education_score += 2\n",
    "    elif edu.lower() == \"bachelor\":\n",
    "        education_score += 3\n",
    "    elif edu.lower() == \"master\":\n",
    "        education_score += 4\n",
    "    elif edu.lower() == \"ph.d\":\n",
    "        education_score += 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8549f154-a43d-4c14-806e-babf9f2df32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying resume score\n",
    "disp = f\"The top ten skills for this job are: {skills}\"\n",
    "resume_score = contact_info_score + skills_score + education_score\n",
    "display = f\"Your resume score is {resume_score}:\"\n",
    "display_scores_1 = f\"Skills: {skills_score}/10\" \n",
    "display_scores_2 = f\"Education: {education_score}\"\n",
    "display_scores_3 = f\"Contact Info: {contact_info_score}\"\n",
    "st.write(disp)\n",
    "st.write(display)\n",
    "st.write(display_scores_1)\n",
    "st.write(display_scores_2)\n",
    "st.write(display_scores_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997956b6-1397-4e78-80a6-5d07aa56cbf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
